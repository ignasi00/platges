{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools to see what happen per pair of images instead of full homography\n",
    "\n",
    "\n",
    "Before start, run something like:\n",
    "\n",
    "`python3 create_list.py correspondances --pto_filename=\"/mnt/c/Users/Ignasi/Downloads/FOTOS_BCN_2022-04-06/panorama_stiching/DJI_0623 - DJI_0627.pto\" --name=prueba --windows`\n",
    "\n",
    "<br>\n",
    "\n",
    "When it works, run something like:\n",
    "\n",
    "`python3 create_platja_models.py --model_name=kk --json_path=./data_lists/prueba/prueba.json --csv_path=./data_lists/prueba/prueba.csv --masks_path=/mnt/c/Users/Ignasi/Downloads/FOTOS_BCN_2022-04-06/panorama_stiching/masks/ --output_path=outputs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python3 create_list.py correspondances --pto_filename=\"/mnt/c/Users/Ignasi/Downloads/platges_per_carpeta/2/1/DJI_0673 - DJI_0680.pto\" --name=2_1 --windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from create_platja_models import load_data, generate_correspondances, create_homographies\n",
    "from frameworks.opencv.homography.stiching import make_stiching, color_matrix_applier, color_blender\n",
    "from frameworks.opencv.homography.utils import compute_dimensions\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [25, 15]\n",
    "np.set_printoptions(formatter={'float' : lambda x: f\"{x:10.3f}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_root = '/mnt/c/Users/Ignasi/Downloads/FOTOS_BCN_2022-04-06/'\n",
    "data_root = '/mnt/c/Users/Ignasi/Downloads/platges_per_carpeta/2/1/'\n",
    "\n",
    "name = '2_1'\n",
    "json_path = f'./data_lists/{name}/{name}.json' # './data_lists/prueba/prueba.json'\n",
    "csv_path = f'./data_lists/{name}/{name}.csv' # './data_lists/prueba/prueba.csv'\n",
    "\n",
    "OFFSET_SUBSET = 4\n",
    "\n",
    "#OFFSET = OFFSET_SUBSET % (len(v_img) - 2 + 1)\n",
    "\n",
    "MAX_HEIGHT = 6000 # None\n",
    "MAX_WIDTH = 8000 # None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJI_0673.JPG\n",
      "DJI_0674.JPG\n",
      "DJI_0675.JPG\n",
      "DJI_0676.JPG\n",
      "DJI_0677.JPG\n",
      "DJI_0678.JPG\n",
      "DJI_0679.JPG\n",
      "DJI_0680.JPG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset, correspondances_df = load_data(json_path, csv_path, data_root=data_root)\n",
    "\n",
    "v_img = []\n",
    "for d in list(dataset[0]):\n",
    "    print(d[1])\n",
    "    v_img.append(d[0])\n",
    "\n",
    "OFFSET = OFFSET_SUBSET % (len(v_img) - 2 + 1)\n",
    "    \n",
    "correspondances_df_subset = correspondances_df[((correspondances_df['img1'] == OFFSET) | (correspondances_df['img2'] == OFFSET)) & ((correspondances_df['img1'] == OFFSET + 1) | (correspondances_df['img2'] == OFFSET + 1))]\n",
    "v_img_subset = v_img[OFFSET : OFFSET + 2]\n",
    "     \n",
    "v_homographies = create_homographies(correspondances_df_subset, v_img_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[     1.000,      0.000,   4422.000],\n",
       "         [     0.000,      1.000,   4118.000],\n",
       "         [     0.000,      0.000,      1.000]]),\n",
       " matrix([[     1.738,     -0.696,   2538.607],\n",
       "         [     0.044,      9.934,      0.065],\n",
       "         [     0.000,      0.002,      0.348]])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_homographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32639, 7766)\n",
      "253474474 px\n",
      "760 423 422 Bytes if each color uses 8 bits (760 MB)\n",
      "3 041 693 688 Bytes if each color uses 32 bits (3041 MB)\n",
      "6 083 387 376 Bytes if each color uses 64 bits (6083 MB)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "composed_img = np.ones(v_img_subset[0].shape[:2])\n",
    "max_x, min_x, max_y, min_y = compute_dimensions(composed_img, composed_img, v_homographies[0])\n",
    "width = int(max_x - min_x + 1)\n",
    "height = int(max_y - min_y + 1)\n",
    "composed_img = np.ones((height, width))\n",
    "\n",
    "current_img = np.ones(v_img_subset[1].shape[:2])\n",
    "max_x, min_x, max_y, min_y = compute_dimensions(composed_img, current_img, v_homographies[1])\n",
    "width = int(max_x - min_x + 1)\n",
    "height = int(max_y - min_y + 1)\n",
    "\n",
    "print((width, height))\n",
    "print(f'{width * height} px')\n",
    "print(f'{width * height * 3 * 8 // 8:,} Bytes if each color uses 8 bits ({int(width * height * 3 * 8 / 8 / 1e6)} MB)'.replace(',', ' '))\n",
    "print(f'{width * height * 3 * 32 // 8:,} Bytes if each color uses 32 bits ({int(width * height * 3 * 32 / 8 / 1e6)} MB)'.replace(',', ' '))\n",
    "print(f'{width * height * 3 * 64 // 8:,} Bytes if each color uses 64 bits ({int(width * height * 3 * 64 / 8 / 1e6)} MB)'.replace(',', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stiched = make_stiching(v_img_subset, v_homographies, matrix_applier=color_matrix_applier, blender=color_blender, max_width=MAX_WIDTH, max_heignt=MAX_HEIGHT)\n",
    "stiched = stiched.astype(int)\n",
    "\n",
    "plt.imshow(stiched)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "handpicked_kps, handpicked_descriptors = generate_correspondances(correspondances_df_subset)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(handpicked_kps))\n",
    "for i, (img, kps, des) in enumerate(zip(v_img_subset[::-1], handpicked_kps[::-1], handpicked_descriptors[::-1])):\n",
    "\n",
    "    try:\n",
    "        kps_x_red, kps_y_red = list(zip(*[(kp.pt[0], kp.pt[1]) for kp, de in zip(kps, des) if de[1] == 0]))\n",
    "    except:\n",
    "        kps_x_red, kps_y_red = [], []\n",
    "    try:\n",
    "        kps_x_cyan, kps_y_cyan = list(zip(*[(kp.pt[0], kp.pt[1]) for kp, de in zip(kps, des) if de[1] == 1]))\n",
    "    except:\n",
    "        kps_x_cyan, kps_y_cyan = [], []\n",
    "    \n",
    "    print(f'Keypoints of the image #{i + 1}')\n",
    "    print([kp.pt for kp in kps], end='\\n---\\n')\n",
    "    \n",
    "    ax[i].imshow(img.astype(np.uint8)) #, cmap=plt.cm.gray)\n",
    "    ax[i].plot(kps_x_cyan, kps_y_cyan, color='cyan', marker='o', linestyle='None', markersize=6)\n",
    "    ax[i].plot(kps_x_red, kps_y_red, color='red', marker='o', linestyle='None', markersize=6)\n",
    "    ax[i].title.set_text(f'image #{i + 1}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
